# Python基础

## 文件

### 读取文件

```python
files = []
filePath = '../爬虫/课程评价/'
for file in os.listdir(filePath):
    if str(file)[-8:] == 'ment.csv':
        files.append(file)
print(files[:5])
```

### CSV转TXT
```python
for file in files:
    data = pd.read_csv(filePath+file, encoding='utf-8', header=None, engine='python')    
    with open('filename.txt','a+', encoding='utf-8') as f:
        for line in data.values:
            f.write((str(line[0])+'\t'+str(line[1])+'\n'))  # 对应csv数据字段
```


### 判断目录是否存在
```python
import os
dirs = '/Users/joseph/work/python/'
if not os.path.exists(dirs):
    os.makedirs(dirs)
```

### 判断文件是否存在
```python
import os
filename = '/Users/joseph/work/python/poem.txt'
if not os.path.exists(filename):
    os.system(r"touch {}".format(path)) #调用系统命令行来创建文件
```
原文链接：<https://blog.csdn.net/u013247765/article/details/79050947>



## 字典

### 字典排序
    freq = sorted(dic.items(), key=lambda x:x[1], reverse=True)



## List

### 统计列表中重复项出现的次数
```python
list1 = ['a','b','a','c','a','c','b']
from collections import Counter
Counter(list1)
Counter({'a': 3, 'b': 2, 'c': 2})
```
来自 <https://blog.csdn.net/angel20082008/article/details/51355921> 

### 二元组/字典数组排序

```python
data = [(1, 'B'), (1, 'A'), (2, 'A'), (0, 'B'), (0, 'a')]
#将x[1].lower()作为返回元组里的第一个元素,按照sorted的排序规律,就会先按字母排序,再按数字排序了
result = sorted(data,key=lambda x:(x[1].lower(),x[0]))
print(result)  #结果为 [(0, 'a'), (1, 'A'), (2, 'A'), (0, 'B'), (1, 'B')]

data = [{'name': '张三', 'height': 175}, {'name': '李四', 'height': 165}, {'name': '王五', 'height': 185}]
#将x['height']最为返回tuple的第个一元素
result = sorted(data,key=lambda x:(x['height'],x['name']))
print(result)  #result 结果:[{'name': '李四', 'height': 165}, {'name': '张三', 'height': 175}, {'name': '王五', 'height': 185}]
```
来自 <https://blog.csdn.net/qq_24076135/java/article/details/78550898>

### 自定义排序

```python
# sorted(nums, key=functools.cmp_to_key(mycmp))  关键句
import functools
class Solution:
    def minNumber(self, nums) -> str:
        def mycmp(a, b):
            if str(a)+str(b) > str(b)+str(a):
                return 1
            return -1
        ans = sorted(nums, key=functools.cmp_to_key(mycmp))
        # print(ans)
        return "".join(str(x) for x in ans)
```

### list 标准库函数

```python
list.append(obj)  # 在列表末尾添加新的对象
list.count(obj)  # 统计某个元素在列表中出现的次数
list.extend(seq)  # 在列表末尾一次性追加另一个序列中的多个值（用新列表扩展原来的列表）
list.index(obj)  # 从列表中找出某个值第一个匹配项的索引位置
list.insert(index, obj)  # 将对象插入列表
list.pop([index=-1])  # 移除列表中的一个元素（默认最后一个元素），并且返回该元素的值
list.remove(obj)  # 移除列表中某个值的第一个匹配项
list.reverse()  # 反向列表中元素
list.sort(cmp=None, key=None, reverse=False)  # 对原列表进行排序
list.index(obj,start,end)  # 对象在列表中的索引号
list.count(obj)  # 对象在列表中出现的总次数
```



## Pandas
### 判断为nan
```python
if pd.isnull(table['0'][0]):
```

### 统计个数
```python
df['id'].value_counts()
```

### 删除指定索引的
DataFrame.drop()中的参数labels是要删除的行或者列的名字，删除行还是列由参数axis控制，axis默认为0即按行删除，要想删除列只需令axis=1。
```python
df.drop([2,'2018-01-01','a'])
df.drop(['V'],axis=1)
```



## 库函数

- [Python标准库模块之heapq](https://www.jianshu.com/p/801318c77ab5)



## pip源

```bash
pip install -U XXX -i https://pypi.tuna.tsinghua.edu.cn/simple
```



## Jupyter

### 去掉警告
```python
import warnings
warnings.filterwarnings('ignore')
```


## 开启http服务器
```bash
python3 -m http.server 80  # 不加默认端口8000
```

## 爬虫
selenium + BeautifulSoup 实现的爬虫

### 开启一个浏览器
```python
options = webdriver.ChromeOptions()
# options.add_argument('--headless')  不显示浏览器
options.add_experimental_option('w3c', False)
browser = webdriver.Chrome('chromedriver.exe的本地地址', options=options)
url = "http://baidu.com"
browser.get(url)  
```

### 用beautifulSoup 解析页面

```python
# 载入一个本地页面:
path = './shuake/学生学习页面.html'
htmlfile = open(path, 'r', encoding='utf-8')
html = htmlfile.read()
soup = BeautifulSoup(html, 'lxml')
# 浏览器页面：
html = browser.page_source
soup = BeautifulSoup(html, 'lxml')
```

### 切换到frame与切回

```python
# 切换到iframe里面点击播放视频
iframe = browser.find_elements_by_tag_name('iframe')[0]
browser.switch_to.frame(iframe)
browser.find_element_by_id('video').click()
# 从frame中切回主文档
browser.switch_to.default_content()
html = browser.page_source
soup = BeautifulSoup(html, 'lxml')
```

### 模拟点击等操作

```python
browser.find_element_by_id('video').click()
# 不要在BeautifulSoup解析出的内容上调用click()等操作，应该用browser对象
```

